{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from finta import TA\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "import seaborn as sn\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "WINDOW = 8 # number of rows to look ahead to see what the price did\n",
    "FETCH_INTERVAL = \"60m\"  # fetch data by interval (including intraday if period < 60 days)\n",
    "        # valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo\n",
    "        # (optional, default is '1d')\n",
    "INTERVAL = '1y'     # use \"period\" instead of start/end\n",
    "        # valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max\n",
    "        # (optional, default is '1mo')\n",
    "symbol = 'FB'      # Symbol of the desired stock\n",
    "INDICATORS = ['RSI', 'MACD', 'STOCH','ADL', 'ATR', 'MOM', 'MFI', 'ROC', 'CCI', 'VORTEX']\n",
    "ROWS_TO_PREDICT = 32\n",
    "# one day 16 rows of data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = yf.download(  # or pdr.get_data_yahoo(...\n",
    "        tickers = symbol,\n",
    "\n",
    "\n",
    "        period = INTERVAL,\n",
    "\n",
    "        interval = FETCH_INTERVAL,\n",
    "\n",
    "        # group by ticker (to access via data['SPY'])\n",
    "        # (optional, default is 'column')\n",
    "        group_by = 'ticker',\n",
    "\n",
    "        # adjust all OHLC automatically\n",
    "        # (optional, default is False)\n",
    "        # auto_adjust = True,\n",
    "\n",
    "        # download pre/post regular market hours data\n",
    "        # (optional, default is False)\n",
    "        prepost = True,\n",
    "\n",
    "        # use threads for mass downloading? (True/False/Integer)\n",
    "        # (optional, default is True)\n",
    "        threads = True,\n",
    "\n",
    "        # proxy URL scheme use use when downloading?\n",
    "        # (optional, default is None)\n",
    "        proxy = None\n",
    "    )\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_class_column(row):\n",
    "    if row['close_shift']-row['close'] > 1.2:\n",
    "        return 1\n",
    "    if row['close_shift'] -row['close']< -1.2:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def print_conf_matrix(test_y, predict, name):\n",
    "    matrix = confusion_matrix(test_y, predict,  labels=[-1, 0, 1])\n",
    "    print(matrix)\n",
    "    ax= plt.subplot()\n",
    "    sn.heatmap(matrix, annot=True, ax = ax) #annot=True to annotate cells\n",
    "\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels', color='white')\n",
    "    ax.set_ylabel('True labels', color='white')\n",
    "    ax.set_title(f'Confusion Matrix for {name}' , color='white')\n",
    "    ax.xaxis.set_ticklabels(['-1','0', '1'], color='white')\n",
    "    ax.yaxis.set_ticklabels(['-1','0', '1'], color='white')\n",
    "    plt.show()\n",
    "\n",
    "def train_model(model,train_x, train_y):\n",
    "    model.fit(train_x, train_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.rename(columns={\"Close\": 'close', \"High\": 'high', \"Low\": 'low', 'Volume': 'volume', 'Open': 'open'}, inplace=True)\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['close'].plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def _get_indicator_data(data):\n",
    "    \"\"\"\n",
    "    Function that uses the finta API to calculate technical indicators used as the features\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    for indicator in INDICATORS:\n",
    "        ind_data = eval('TA.' + indicator + '(data)')\n",
    "        if not isinstance(ind_data, pd.DataFrame):\n",
    "            ind_data = ind_data.to_frame()\n",
    "        data = pd.concat([data, ind_data], axis=1)\n",
    "    # data.rename(columns={\"14 period EMV.\": '14 period EMV'}, inplace=True)\n",
    "\n",
    "    # Also calculate moving averages for features\n",
    "    data['ema50'] = data['close'] / data['close'].ewm(50).mean()\n",
    "    data['ema21'] = data['close'] / data['close'].ewm(21).mean()\n",
    "    # data['ema15'] = data['close'] / data['close'].ewm(ROWS_TO_PREDICT).mean()\n",
    "    data['ema5'] = data['close'] / data['close'].ewm(5).mean()\n",
    "\n",
    "    # Instead of using the actual volume value (which changes over time), we normalize it with a moving volume average\n",
    "    # data['normVol'] = data['volume'] / data['volume'].ewm(5).mean()\n",
    "\n",
    "    # Remove columns that won't be used as features\n",
    "    del (data['open'])\n",
    "    del (data['high'])\n",
    "    del (data['low'])\n",
    "    del (data['volume'])\n",
    "    del (data['Adj Close'])\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score = defaultdict(list)\n",
    "for rows_to_predict in range(1,64):\n",
    "    data = df.copy()\n",
    "    data = _get_indicator_data(data)\n",
    "\n",
    "    data['close_shift'] = data.shift(-WINDOW)['close']\n",
    "    data['class_column'] = data.apply(create_class_column, axis=1)\n",
    "    # Class divide\n",
    "    print(data['class_column'].value_counts())\n",
    "\n",
    "\n",
    "    del (data['close'])\n",
    "    del (data['close_shift'])\n",
    "    data = data.dropna()\n",
    "    train_set = data.iloc[:-rows_to_predict]\n",
    "    test_set =data.iloc[-rows_to_predict:]\n",
    "\n",
    "    y = data['class_column']\n",
    "    features = [x for x in data.columns if x not in ['class_column']]\n",
    "    x = data[features]\n",
    "\n",
    "    x_train= x.iloc[:-ROWS_TO_PREDICT]\n",
    "    y_train= y.iloc[:-ROWS_TO_PREDICT]\n",
    "    x_test =x.iloc[-ROWS_TO_PREDICT:]\n",
    "    y_test=y.iloc[-ROWS_TO_PREDICT:]\n",
    "\n",
    "    classifiers = dict()\n",
    "\n",
    "    classifiers['DecisionTreeClassifier 1'] = DecisionTreeClassifier(max_depth=10, random_state=0,criterion='gini',splitter='best')\n",
    "    classifiers['DecisionTreeClassifier 2'] = DecisionTreeClassifier(max_depth=10, random_state=0,criterion='gini',splitter='random')\n",
    "    classifiers['DecisionTreeClassifier 3'] = DecisionTreeClassifier(max_depth=10, random_state=0,criterion='entropy',splitter='best')\n",
    "    classifiers['DecisionTreeClassifier 4'] = DecisionTreeClassifier(max_depth=10, random_state=0,criterion='entropy',splitter='random')\n",
    "    classifiers['DecisionTreeClassifier 5'] = DecisionTreeClassifier(random_state=0,criterion='gini',splitter='best')\n",
    "    classifiers['DecisionTreeClassifier 6'] = DecisionTreeClassifier(random_state=0,criterion='gini',splitter='random')\n",
    "    classifiers['DecisionTreeClassifier 7'] = DecisionTreeClassifier(random_state=0,criterion='entropy',splitter='best')\n",
    "    classifiers['DecisionTreeClassifier 8'] = DecisionTreeClassifier(random_state=0,criterion='entropy',splitter='random')\n",
    "\n",
    "    classifiers['RandomForestClassifier 1'] = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0,criterion='gini')\n",
    "    classifiers['RandomForestClassifier 2'] = RandomForestClassifier(n_estimators=1000, max_depth=2, random_state=0,criterion='gini')\n",
    "    classifiers['RandomForestClassifier 3'] = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=0,criterion='gini')\n",
    "    classifiers['RandomForestClassifier 4'] = RandomForestClassifier(n_estimators=1000, max_depth=3, random_state=0,criterion='gini')\n",
    "    classifiers['RandomForestClassifier 5'] = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0,criterion='entropy')\n",
    "    classifiers['RandomForestClassifier 6'] = RandomForestClassifier(n_estimators=1000, max_depth=2, random_state=0,criterion='entropy')\n",
    "    classifiers['RandomForestClassifier 7'] = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=0,criterion='entropy')\n",
    "    classifiers['RandomForestClassifier 8'] = RandomForestClassifier(n_estimators=1000, max_depth=3, random_state=0,criterion='entropy')\n",
    "\n",
    "    classifiers['GradientBoostingClassifier 1'] = GradientBoostingClassifier(n_estimators=100,random_state=0,criterion='friedman_mse',max_depth=3, learning_rate=0.1)\n",
    "    classifiers['GradientBoostingClassifier 2'] = GradientBoostingClassifier(n_estimators=100,random_state=0,criterion='friedman_mse',max_depth=3, learning_rate=0.3)\n",
    "    classifiers['GradientBoostingClassifier 3'] = GradientBoostingClassifier(n_estimators=100,random_state=0,criterion='friedman_mse',max_depth=3, learning_rate=0.5)\n",
    "    classifiers['GradientBoostingClassifier 4'] = GradientBoostingClassifier(n_estimators=100,random_state=0,criterion='friedman_mse',max_depth=3, learning_rate=1)\n",
    "    #\n",
    "    classifiers['GradientBoostingClassifier 5'] = GradientBoostingClassifier(n_estimators=1000,random_state=0,criterion='friedman_mse',max_depth=3, learning_rate=0.1)\n",
    "    classifiers['GradientBoostingClassifier 6'] = GradientBoostingClassifier(n_estimators=1000,random_state=0,criterion='friedman_mse',max_depth=3, learning_rate=0.3)\n",
    "    classifiers['GradientBoostingClassifier 7'] = GradientBoostingClassifier(n_estimators=1000,random_state=0,criterion='friedman_mse',max_depth=3, learning_rate=0.5)\n",
    "    classifiers['GradientBoostingClassifier 8'] = GradientBoostingClassifier(n_estimators=1000,random_state=0,criterion='friedman_mse',max_depth=3, learning_rate=1)\n",
    "\n",
    "    classifiers['GradientBoostingClassifier 9'] = GradientBoostingClassifier(n_estimators=1000,random_state=0,criterion='friedman_mse',max_depth=2, learning_rate=0.1)\n",
    "    classifiers['GradientBoostingClassifier 10'] = GradientBoostingClassifier(n_estimators=1000,random_state=0,criterion='friedman_mse',max_depth=2, learning_rate=0.3)\n",
    "    classifiers['GradientBoostingClassifier 11'] = GradientBoostingClassifier(n_estimators=1000,random_state=0,criterion='friedman_mse',max_depth=2, learning_rate=0.5)\n",
    "    classifiers['GradientBoostingClassifier 12'] = GradientBoostingClassifier(n_estimators=1000,random_state=0,criterion='friedman_mse',max_depth=2, learning_rate=1)\n",
    "\n",
    "    predictions= dict()\n",
    "    for k,v in classifiers.items():\n",
    "        print(\"Calculate: \", k)\n",
    "        train_model(v,x_train,y_train)\n",
    "        predictions[k] = v.predict(x_test)\n",
    "        score[k].append(accuracy_score(y_test.values, predictions[k]))\n",
    "        # print('Score: ',  score[k] )\n",
    "        # print_conf_matrix(test_y, predictions[k], k)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "headers = [\"Classifier type\", \"Accuracy\"]\n",
    "score_df = pd.DataFrame(score.items(), columns=headers)\n",
    "print(tabulate(score_df, headers, tablefmt=\"psql\"))\n",
    "headers = [\"Classifier type\", \"Accuracy\"]\n",
    "new_headers = [f'Predict rows  {i}' for i in range(1,64)]\n",
    "headers2 = [\"Classifier type\",] + new_headers\n",
    "score_df = pd.DataFrame(score.items(), columns=headers)\n",
    "accuracy_df = pd.DataFrame(score_df['Accuracy'].tolist(), index= score_df.index, columns=new_headers)\n",
    "score_df = score_df.drop('Accuracy', 1)\n",
    "f_out = pd.merge(score_df, accuracy_df, how='left', left_index=True, right_index=True)\n",
    "print(tabulate(f_out, headers2, tablefmt=\"psql\"))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "magisterka_analiza",
   "language": "python",
   "display_name": "Python magisterka"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}