{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 466,
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from finta import TA\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "import seaborn as sn\n",
    "from tabulate import tabulate\n",
    "from xgboost import XGBClassifier\n",
    "from ta import add_all_ta_features\n",
    "from sklearn.feature_selection import RFE\n",
    "import xgboost as xgb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "outputs": [],
   "source": [
    "WINDOW = 16 # number of rows to look ahead to see what the price did\n",
    "FETCH_INTERVAL = \"60m\"  # fetch data by interval (including intraday if period < 60 days)\n",
    "        # valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo\n",
    "        # (optional, default is '1d')\n",
    "INTERVAL = '2y'     # use \"period\" instead of start/end\n",
    "        # valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max\n",
    "        # (optional, default is '1mo')\n",
    "symbol = 'AAPL'      # Symbol of the desired stock\n",
    "\n",
    "# one day 16 rows of data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                 Open        High         Low       Close  \\\nDatetime                                                                    \n2019-08-21 04:00:00-04:00   52.775000   53.110000   52.775000   53.050000   \n2019-08-21 05:00:00-04:00   53.045000   53.150000   53.045000   53.150000   \n2019-08-21 06:00:00-04:00   53.152500   53.200000   53.045000   53.080000   \n2019-08-21 07:00:00-04:00   53.112500   53.112500   53.000000   53.070000   \n2019-08-21 08:00:00-04:00   53.050000   53.100000   53.000000   53.065000   \n...                               ...         ...         ...         ...   \n2021-08-20 13:30:00-04:00  147.912003  147.994995  147.550003  147.720001   \n2021-08-20 14:30:00-04:00  147.714996  148.165894  147.559998  148.084793   \n2021-08-20 15:30:00-04:00  148.087006  148.289993  147.945007  148.190002   \n2021-08-20 16:00:00-04:00  148.190000  148.300000  147.616000  148.190000   \n2021-08-20 17:00:00-04:00  148.170000  148.280000  142.382000  148.260000   \n\n                            Adj Close   Volume  \nDatetime                                        \n2019-08-21 04:00:00-04:00   53.050000        0  \n2019-08-21 05:00:00-04:00   53.150000        0  \n2019-08-21 06:00:00-04:00   53.080000        0  \n2019-08-21 07:00:00-04:00   53.070000        0  \n2019-08-21 08:00:00-04:00   53.065000        0  \n...                               ...      ...  \n2021-08-20 13:30:00-04:00  147.720001  4405041  \n2021-08-20 14:30:00-04:00  148.084793  4758189  \n2021-08-20 15:30:00-04:00  148.190002  6188690  \n2021-08-20 16:00:00-04:00  148.190000  5268304  \n2021-08-20 17:00:00-04:00  148.260000        0  \n\n[8377 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n    </tr>\n    <tr>\n      <th>Datetime</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-08-21 04:00:00-04:00</th>\n      <td>52.775000</td>\n      <td>53.110000</td>\n      <td>52.775000</td>\n      <td>53.050000</td>\n      <td>53.050000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2019-08-21 05:00:00-04:00</th>\n      <td>53.045000</td>\n      <td>53.150000</td>\n      <td>53.045000</td>\n      <td>53.150000</td>\n      <td>53.150000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2019-08-21 06:00:00-04:00</th>\n      <td>53.152500</td>\n      <td>53.200000</td>\n      <td>53.045000</td>\n      <td>53.080000</td>\n      <td>53.080000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2019-08-21 07:00:00-04:00</th>\n      <td>53.112500</td>\n      <td>53.112500</td>\n      <td>53.000000</td>\n      <td>53.070000</td>\n      <td>53.070000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2019-08-21 08:00:00-04:00</th>\n      <td>53.050000</td>\n      <td>53.100000</td>\n      <td>53.000000</td>\n      <td>53.065000</td>\n      <td>53.065000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2021-08-20 13:30:00-04:00</th>\n      <td>147.912003</td>\n      <td>147.994995</td>\n      <td>147.550003</td>\n      <td>147.720001</td>\n      <td>147.720001</td>\n      <td>4405041</td>\n    </tr>\n    <tr>\n      <th>2021-08-20 14:30:00-04:00</th>\n      <td>147.714996</td>\n      <td>148.165894</td>\n      <td>147.559998</td>\n      <td>148.084793</td>\n      <td>148.084793</td>\n      <td>4758189</td>\n    </tr>\n    <tr>\n      <th>2021-08-20 15:30:00-04:00</th>\n      <td>148.087006</td>\n      <td>148.289993</td>\n      <td>147.945007</td>\n      <td>148.190002</td>\n      <td>148.190002</td>\n      <td>6188690</td>\n    </tr>\n    <tr>\n      <th>2021-08-20 16:00:00-04:00</th>\n      <td>148.190000</td>\n      <td>148.300000</td>\n      <td>147.616000</td>\n      <td>148.190000</td>\n      <td>148.190000</td>\n      <td>5268304</td>\n    </tr>\n    <tr>\n      <th>2021-08-20 17:00:00-04:00</th>\n      <td>148.170000</td>\n      <td>148.280000</td>\n      <td>142.382000</td>\n      <td>148.260000</td>\n      <td>148.260000</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8377 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = yf.download(  # or pdr.get_data_yahoo(...\n",
    "        tickers = symbol,\n",
    "\n",
    "\n",
    "        period = INTERVAL,\n",
    "\n",
    "        interval = FETCH_INTERVAL,\n",
    "\n",
    "        # group by ticker (to access via data['SPY'])\n",
    "        # (optional, default is 'column')\n",
    "        group_by = 'ticker',\n",
    "\n",
    "        # adjust all OHLC automatically\n",
    "        # (optional, default is False)\n",
    "        # auto_adjust = True,\n",
    "\n",
    "        # download pre/post regular market hours data\n",
    "        # (optional, default is False)\n",
    "        prepost = True,\n",
    "\n",
    "        # use threads for mass downloading? (True/False/Integer)\n",
    "        # (optional, default is True)\n",
    "        threads = True,\n",
    "\n",
    "        # proxy URL scheme use use when downloading?\n",
    "        # (optional, default is None)\n",
    "        proxy = None\n",
    "    )\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "outputs": [],
   "source": [
    "# data = pd.read_csv('C:\\\\Users\\\\exomat\\\\Desktop\\\\repo\\\\magisterka_analiza\\\\data\\\\preprocess_new\\\\AAPL_2y_8_11_05_2021 09_00_35_full.csv', index_col='Datetime')\n",
    "# data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "outputs": [],
   "source": [
    "data.rename(columns={\"Close\": 'close', \"High\": 'high', \"Low\": 'low', 'Volume': 'volume', 'Open': 'open'}, inplace=True)\n",
    "data.head(10)\n",
    "important_columns = ['open', 'high', 'low','close','volume']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 8377 entries, 2019-08-21 04:00:00-04:00 to 2021-08-20 17:00:00-04:00\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   open       8377 non-null   float64\n",
      " 1   high       8377 non-null   float64\n",
      " 2   low        8377 non-null   float64\n",
      " 3   close      8377 non-null   float64\n",
      " 4   Adj Close  8377 non-null   float64\n",
      " 5   volume     8377 non-null   int64  \n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 458.1 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "outputs": [],
   "source": [
    "\n",
    "def calculate_diffs(diff_number, col_name):\n",
    "    new_col_name = f'{col_name}_{diff_number}'\n",
    "    data[new_col_name] = data[col_name].diff(diff_number)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "outputs": [],
   "source": [
    "# for name in important_columns:\n",
    "#     for i in range(1, 11):\n",
    "#         calculate_diffs(i, name)\n",
    "#\n",
    "# data.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "outputs": [],
   "source": [
    "# data\n",
    "# data.set_index(pd.DatetimeIndex(data['Datetime']))\n",
    "# data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "#\n",
    "# data.plot(kind='line',x='Datetime',y='close',ax=ax)\n",
    "#\n",
    "# every_nth = 4\n",
    "# for n, label in enumerate(ax.xaxis.get_ticklabels()):\n",
    "#     if n % every_nth != 0:\n",
    "#         label.set_visible(False)\n",
    "#\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# sns.set()\n",
    "# ax = data['open'].plot()\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.ylabel('Kurs akcji [$]', rotation=90)\n",
    "# plt.xlabel('Czas')\n",
    "# plt.legend(['Close'], ncol=1, loc='upper left');\n",
    "# plt.show()\n",
    "#\n",
    "# fig = ax.get_figure()\n",
    "# fig.savefig('asdf.png', dpi=300, bbox_inches=\"tight\")\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "outputs": [],
   "source": [
    "# data['close_pct'] = data['close'].pct_change()\n",
    "# data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "outputs": [
    {
     "data": {
      "text/plain": "              open         high          low        close    Adj Close  \\\ncount  8377.000000  8377.000000  8377.000000  8377.000000  8377.000000   \nmean    101.051622   101.468736   100.545858   101.056083   101.056083   \nstd      29.983177    30.346019    29.813513    29.980169    29.980169   \nmin      50.250000    50.467500    50.250000    50.357500    50.357500   \n25%      71.577500    71.949997    71.217500    71.625000    71.625000   \n50%     111.446251   111.962500   110.590000   111.410000   111.410000   \n75%     126.910004   127.250000   126.360000   126.915001   126.915001   \nmax     151.410000   438.440000   151.290000   151.670000   151.670000   \n\n             volume  \ncount  8.377000e+03  \nmean   3.809317e+06  \nstd    6.934562e+06  \nmin    0.000000e+00  \n25%    0.000000e+00  \n50%    0.000000e+00  \n75%    5.486126e+06  \nmax    9.845401e+07  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>Adj Close</th>\n      <th>volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>8377.000000</td>\n      <td>8377.000000</td>\n      <td>8377.000000</td>\n      <td>8377.000000</td>\n      <td>8377.000000</td>\n      <td>8.377000e+03</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>101.051622</td>\n      <td>101.468736</td>\n      <td>100.545858</td>\n      <td>101.056083</td>\n      <td>101.056083</td>\n      <td>3.809317e+06</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>29.983177</td>\n      <td>30.346019</td>\n      <td>29.813513</td>\n      <td>29.980169</td>\n      <td>29.980169</td>\n      <td>6.934562e+06</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>50.250000</td>\n      <td>50.467500</td>\n      <td>50.250000</td>\n      <td>50.357500</td>\n      <td>50.357500</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>71.577500</td>\n      <td>71.949997</td>\n      <td>71.217500</td>\n      <td>71.625000</td>\n      <td>71.625000</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>111.446251</td>\n      <td>111.962500</td>\n      <td>110.590000</td>\n      <td>111.410000</td>\n      <td>111.410000</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>126.910004</td>\n      <td>127.250000</td>\n      <td>126.360000</td>\n      <td>126.915001</td>\n      <td>126.915001</td>\n      <td>5.486126e+06</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>151.410000</td>\n      <td>438.440000</td>\n      <td>151.290000</td>\n      <td>151.670000</td>\n      <td>151.670000</td>\n      <td>9.845401e+07</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "outputs": [],
   "source": [
    "from ta import add_all_ta_features\n",
    "\n",
    "def _get_indicator_data(data):\n",
    "\n",
    "    data = add_all_ta_features(\n",
    "        data, open=\"open\", high=\"high\", low=\"low\", close=\"close\", volume=\"volume\", fillna=True)\n",
    "\n",
    "    return data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "outputs": [
    {
     "data": {
      "text/plain": "                                 open        high         low       close  \\\nDatetime                                                                    \n2019-08-21 04:00:00-04:00   52.775000   53.110000   52.775000   53.050000   \n2019-08-21 05:00:00-04:00   53.045000   53.150000   53.045000   53.150000   \n2019-08-21 06:00:00-04:00   53.152500   53.200000   53.045000   53.080000   \n2019-08-21 07:00:00-04:00   53.112500   53.112500   53.000000   53.070000   \n2019-08-21 08:00:00-04:00   53.050000   53.100000   53.000000   53.065000   \n...                               ...         ...         ...         ...   \n2021-08-20 13:30:00-04:00  147.912003  147.994995  147.550003  147.720001   \n2021-08-20 14:30:00-04:00  147.714996  148.165894  147.559998  148.084793   \n2021-08-20 15:30:00-04:00  148.087006  148.289993  147.945007  148.190002   \n2021-08-20 16:00:00-04:00  148.190000  148.300000  147.616000  148.190000   \n2021-08-20 17:00:00-04:00  148.170000  148.280000  142.382000  148.260000   \n\n                            Adj Close   volume  \nDatetime                                        \n2019-08-21 04:00:00-04:00   53.050000        0  \n2019-08-21 05:00:00-04:00   53.150000        0  \n2019-08-21 06:00:00-04:00   53.080000        0  \n2019-08-21 07:00:00-04:00   53.070000        0  \n2019-08-21 08:00:00-04:00   53.065000        0  \n...                               ...      ...  \n2021-08-20 13:30:00-04:00  147.720001  4405041  \n2021-08-20 14:30:00-04:00  148.084793  4758189  \n2021-08-20 15:30:00-04:00  148.190002  6188690  \n2021-08-20 16:00:00-04:00  148.190000  5268304  \n2021-08-20 17:00:00-04:00  148.260000        0  \n\n[8377 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>Adj Close</th>\n      <th>volume</th>\n    </tr>\n    <tr>\n      <th>Datetime</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-08-21 04:00:00-04:00</th>\n      <td>52.775000</td>\n      <td>53.110000</td>\n      <td>52.775000</td>\n      <td>53.050000</td>\n      <td>53.050000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2019-08-21 05:00:00-04:00</th>\n      <td>53.045000</td>\n      <td>53.150000</td>\n      <td>53.045000</td>\n      <td>53.150000</td>\n      <td>53.150000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2019-08-21 06:00:00-04:00</th>\n      <td>53.152500</td>\n      <td>53.200000</td>\n      <td>53.045000</td>\n      <td>53.080000</td>\n      <td>53.080000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2019-08-21 07:00:00-04:00</th>\n      <td>53.112500</td>\n      <td>53.112500</td>\n      <td>53.000000</td>\n      <td>53.070000</td>\n      <td>53.070000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2019-08-21 08:00:00-04:00</th>\n      <td>53.050000</td>\n      <td>53.100000</td>\n      <td>53.000000</td>\n      <td>53.065000</td>\n      <td>53.065000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2021-08-20 13:30:00-04:00</th>\n      <td>147.912003</td>\n      <td>147.994995</td>\n      <td>147.550003</td>\n      <td>147.720001</td>\n      <td>147.720001</td>\n      <td>4405041</td>\n    </tr>\n    <tr>\n      <th>2021-08-20 14:30:00-04:00</th>\n      <td>147.714996</td>\n      <td>148.165894</td>\n      <td>147.559998</td>\n      <td>148.084793</td>\n      <td>148.084793</td>\n      <td>4758189</td>\n    </tr>\n    <tr>\n      <th>2021-08-20 15:30:00-04:00</th>\n      <td>148.087006</td>\n      <td>148.289993</td>\n      <td>147.945007</td>\n      <td>148.190002</td>\n      <td>148.190002</td>\n      <td>6188690</td>\n    </tr>\n    <tr>\n      <th>2021-08-20 16:00:00-04:00</th>\n      <td>148.190000</td>\n      <td>148.300000</td>\n      <td>147.616000</td>\n      <td>148.190000</td>\n      <td>148.190000</td>\n      <td>5268304</td>\n    </tr>\n    <tr>\n      <th>2021-08-20 17:00:00-04:00</th>\n      <td>148.170000</td>\n      <td>148.280000</td>\n      <td>142.382000</td>\n      <td>148.260000</td>\n      <td>148.260000</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8377 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['open', 'high', 'low', 'close', 'Adj Close', 'volume'], dtype='object')"
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "outputs": [],
   "source": [
    "def create_class_column(row, lowest_threshold, higher_threshold):\n",
    "    if row['close_shift'] - row['close'] > higher_threshold:\n",
    "        return 1\n",
    "    if row['close_shift'] - row['close'] < lowest_threshold:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\ta\\trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[i] = 100 * (self._dip[i] / self._trs[i])\n",
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\ta\\trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[i] = 100 * (self._din[i] / self._trs[i])\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                 open        high         low       close  \\\nDatetime                                                                    \n2019-08-21 04:00:00-04:00   52.775000   53.110000   52.775000   53.050000   \n2019-08-21 05:00:00-04:00   53.045000   53.150000   53.045000   53.150000   \n2019-08-21 06:00:00-04:00   53.152500   53.200000   53.045000   53.080000   \n2019-08-21 07:00:00-04:00   53.112500   53.112500   53.000000   53.070000   \n2019-08-21 08:00:00-04:00   53.050000   53.100000   53.000000   53.065000   \n...                               ...         ...         ...         ...   \n2021-08-20 13:30:00-04:00  147.912003  147.994995  147.550003  147.720001   \n2021-08-20 14:30:00-04:00  147.714996  148.165894  147.559998  148.084793   \n2021-08-20 15:30:00-04:00  148.087006  148.289993  147.945007  148.190002   \n2021-08-20 16:00:00-04:00  148.190000  148.300000  147.616000  148.190000   \n2021-08-20 17:00:00-04:00  148.170000  148.280000  142.382000  148.260000   \n\n                            Adj Close   volume    volume_adi  volume_obv  \\\nDatetime                                                                   \n2019-08-21 04:00:00-04:00   53.050000        0  0.000000e+00           0   \n2019-08-21 05:00:00-04:00   53.150000        0  0.000000e+00           0   \n2019-08-21 06:00:00-04:00   53.080000        0  0.000000e+00           0   \n2019-08-21 07:00:00-04:00   53.070000        0  0.000000e+00           0   \n2019-08-21 08:00:00-04:00   53.065000        0  0.000000e+00           0   \n...                               ...      ...           ...         ...   \n2021-08-20 13:30:00-04:00  147.720001  4405041  1.740461e+09   510276027   \n2021-08-20 14:30:00-04:00  148.084793  4758189  1.743945e+09   515034216   \n2021-08-20 15:30:00-04:00  148.190002  6188690  1.746547e+09   521222906   \n2021-08-20 16:00:00-04:00  148.190000  5268304  1.750120e+09   515954602   \n2021-08-20 17:00:00-04:00  148.260000        0  1.750120e+09   515954602   \n\n                           volume_cmf      volume_fi  ...  momentum_ao  \\\nDatetime                                              ...                \n2019-08-21 04:00:00-04:00    0.000000       0.000000  ...     0.000000   \n2019-08-21 05:00:00-04:00    0.000000       0.000000  ...     0.000000   \n2019-08-21 06:00:00-04:00    0.000000       0.000000  ...     0.000000   \n2019-08-21 07:00:00-04:00    0.000000       0.000000  ...     0.000000   \n2019-08-21 08:00:00-04:00    0.000000       0.000000  ...     0.000000   \n...                               ...            ...  ...          ...   \n2021-08-20 13:30:00-04:00    0.054954  481052.780475  ...     1.250673   \n2021-08-20 14:30:00-04:00    0.033182  660295.049504  ...     1.318058   \n2021-08-20 15:30:00-04:00    0.170270  658982.621843  ...     1.283838   \n2021-08-20 16:00:00-04:00    0.332275  564840.409856  ...     1.345144   \n2021-08-20 17:00:00-04:00    0.235600  484148.922733  ...     0.861492   \n\n                           momentum_kama  momentum_roc  momentum_ppo  \\\nDatetime                                                               \n2019-08-21 04:00:00-04:00      53.050000      0.000000      0.000000   \n2019-08-21 05:00:00-04:00      53.094125      0.000000      0.000000   \n2019-08-21 06:00:00-04:00      53.087931      0.000000      0.000000   \n2019-08-21 07:00:00-04:00      53.080061      0.000000      0.000000   \n2019-08-21 08:00:00-04:00      53.073436      0.000000      0.000000   \n...                                  ...           ...           ...   \n2021-08-20 13:30:00-04:00     146.998141      0.695297      6.479453   \n2021-08-20 14:30:00-04:00     147.190885      1.047283      6.175124   \n2021-08-20 15:30:00-04:00     147.387734      1.333426      8.251022   \n2021-08-20 16:00:00-04:00     147.540621      1.188119      8.201423   \n2021-08-20 17:00:00-04:00     147.626934      1.263575     -1.120546   \n\n                           momentum_ppo_signal  momentum_ppo_hist  others_dr  \\\nDatetime                                                                       \n2019-08-21 04:00:00-04:00             0.000000           0.000000 -47.504397   \n2019-08-21 05:00:00-04:00             0.000000           0.000000   0.188501   \n2019-08-21 06:00:00-04:00             0.000000           0.000000  -0.131703   \n2019-08-21 07:00:00-04:00             0.000000           0.000000  -0.018839   \n2019-08-21 08:00:00-04:00             0.000000           0.000000  -0.009422   \n...                                        ...                ...        ...   \n2021-08-20 13:30:00-04:00            -5.881436          12.360889  -0.133651   \n2021-08-20 14:30:00-04:00            -3.470124           9.645248   0.246948   \n2021-08-20 15:30:00-04:00            -1.125895           9.376917   0.071047   \n2021-08-20 16:00:00-04:00             0.739569           7.461854  -0.000002   \n2021-08-20 17:00:00-04:00             0.367546          -1.488091   0.047237   \n\n                           others_dlr   others_cr  close_shift  \nDatetime                                                        \n2019-08-21 04:00:00-04:00    0.000000    0.000000      53.3475  \n2019-08-21 05:00:00-04:00    0.188324    0.188501      53.2000  \n2019-08-21 06:00:00-04:00   -0.131790    0.056550      52.9025  \n2019-08-21 07:00:00-04:00   -0.018841    0.037700      53.0250  \n2019-08-21 08:00:00-04:00   -0.009422    0.028275      53.1950  \n...                               ...         ...          ...  \n2021-08-20 13:30:00-04:00   -0.133740  178.454291          NaN  \n2021-08-20 14:30:00-04:00    0.246644  179.141929          NaN  \n2021-08-20 15:30:00-04:00    0.071021  179.340250          NaN  \n2021-08-20 16:00:00-04:00   -0.000002  179.340245          NaN  \n2021-08-20 17:00:00-04:00    0.047226  179.472196          NaN  \n\n[8377 rows x 90 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>Adj Close</th>\n      <th>volume</th>\n      <th>volume_adi</th>\n      <th>volume_obv</th>\n      <th>volume_cmf</th>\n      <th>volume_fi</th>\n      <th>...</th>\n      <th>momentum_ao</th>\n      <th>momentum_kama</th>\n      <th>momentum_roc</th>\n      <th>momentum_ppo</th>\n      <th>momentum_ppo_signal</th>\n      <th>momentum_ppo_hist</th>\n      <th>others_dr</th>\n      <th>others_dlr</th>\n      <th>others_cr</th>\n      <th>close_shift</th>\n    </tr>\n    <tr>\n      <th>Datetime</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-08-21 04:00:00-04:00</th>\n      <td>52.775000</td>\n      <td>53.110000</td>\n      <td>52.775000</td>\n      <td>53.050000</td>\n      <td>53.050000</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>53.050000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-47.504397</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>53.3475</td>\n    </tr>\n    <tr>\n      <th>2019-08-21 05:00:00-04:00</th>\n      <td>53.045000</td>\n      <td>53.150000</td>\n      <td>53.045000</td>\n      <td>53.150000</td>\n      <td>53.150000</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>53.094125</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.188501</td>\n      <td>0.188324</td>\n      <td>0.188501</td>\n      <td>53.2000</td>\n    </tr>\n    <tr>\n      <th>2019-08-21 06:00:00-04:00</th>\n      <td>53.152500</td>\n      <td>53.200000</td>\n      <td>53.045000</td>\n      <td>53.080000</td>\n      <td>53.080000</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>53.087931</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-0.131703</td>\n      <td>-0.131790</td>\n      <td>0.056550</td>\n      <td>52.9025</td>\n    </tr>\n    <tr>\n      <th>2019-08-21 07:00:00-04:00</th>\n      <td>53.112500</td>\n      <td>53.112500</td>\n      <td>53.000000</td>\n      <td>53.070000</td>\n      <td>53.070000</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>53.080061</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-0.018839</td>\n      <td>-0.018841</td>\n      <td>0.037700</td>\n      <td>53.0250</td>\n    </tr>\n    <tr>\n      <th>2019-08-21 08:00:00-04:00</th>\n      <td>53.050000</td>\n      <td>53.100000</td>\n      <td>53.000000</td>\n      <td>53.065000</td>\n      <td>53.065000</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>53.073436</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-0.009422</td>\n      <td>-0.009422</td>\n      <td>0.028275</td>\n      <td>53.1950</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2021-08-20 13:30:00-04:00</th>\n      <td>147.912003</td>\n      <td>147.994995</td>\n      <td>147.550003</td>\n      <td>147.720001</td>\n      <td>147.720001</td>\n      <td>4405041</td>\n      <td>1.740461e+09</td>\n      <td>510276027</td>\n      <td>0.054954</td>\n      <td>481052.780475</td>\n      <td>...</td>\n      <td>1.250673</td>\n      <td>146.998141</td>\n      <td>0.695297</td>\n      <td>6.479453</td>\n      <td>-5.881436</td>\n      <td>12.360889</td>\n      <td>-0.133651</td>\n      <td>-0.133740</td>\n      <td>178.454291</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2021-08-20 14:30:00-04:00</th>\n      <td>147.714996</td>\n      <td>148.165894</td>\n      <td>147.559998</td>\n      <td>148.084793</td>\n      <td>148.084793</td>\n      <td>4758189</td>\n      <td>1.743945e+09</td>\n      <td>515034216</td>\n      <td>0.033182</td>\n      <td>660295.049504</td>\n      <td>...</td>\n      <td>1.318058</td>\n      <td>147.190885</td>\n      <td>1.047283</td>\n      <td>6.175124</td>\n      <td>-3.470124</td>\n      <td>9.645248</td>\n      <td>0.246948</td>\n      <td>0.246644</td>\n      <td>179.141929</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2021-08-20 15:30:00-04:00</th>\n      <td>148.087006</td>\n      <td>148.289993</td>\n      <td>147.945007</td>\n      <td>148.190002</td>\n      <td>148.190002</td>\n      <td>6188690</td>\n      <td>1.746547e+09</td>\n      <td>521222906</td>\n      <td>0.170270</td>\n      <td>658982.621843</td>\n      <td>...</td>\n      <td>1.283838</td>\n      <td>147.387734</td>\n      <td>1.333426</td>\n      <td>8.251022</td>\n      <td>-1.125895</td>\n      <td>9.376917</td>\n      <td>0.071047</td>\n      <td>0.071021</td>\n      <td>179.340250</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2021-08-20 16:00:00-04:00</th>\n      <td>148.190000</td>\n      <td>148.300000</td>\n      <td>147.616000</td>\n      <td>148.190000</td>\n      <td>148.190000</td>\n      <td>5268304</td>\n      <td>1.750120e+09</td>\n      <td>515954602</td>\n      <td>0.332275</td>\n      <td>564840.409856</td>\n      <td>...</td>\n      <td>1.345144</td>\n      <td>147.540621</td>\n      <td>1.188119</td>\n      <td>8.201423</td>\n      <td>0.739569</td>\n      <td>7.461854</td>\n      <td>-0.000002</td>\n      <td>-0.000002</td>\n      <td>179.340245</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2021-08-20 17:00:00-04:00</th>\n      <td>148.170000</td>\n      <td>148.280000</td>\n      <td>142.382000</td>\n      <td>148.260000</td>\n      <td>148.260000</td>\n      <td>0</td>\n      <td>1.750120e+09</td>\n      <td>515954602</td>\n      <td>0.235600</td>\n      <td>484148.922733</td>\n      <td>...</td>\n      <td>0.861492</td>\n      <td>147.626934</td>\n      <td>1.263575</td>\n      <td>-1.120546</td>\n      <td>0.367546</td>\n      <td>-1.488091</td>\n      <td>0.047237</td>\n      <td>0.047226</td>\n      <td>179.472196</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>8377 rows × 90 columns</p>\n</div>"
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = _get_indicator_data(data)\n",
    "data['close_shift'] = data.shift(-WINDOW)['close']\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "outputs": [
    {
     "data": {
      "text/plain": "                                 open        high         low       close  \\\nDatetime                                                                    \n2019-08-21 04:00:00-04:00   52.775000   53.110000   52.775000   53.050000   \n2019-08-21 05:00:00-04:00   53.045000   53.150000   53.045000   53.150000   \n2019-08-21 06:00:00-04:00   53.152500   53.200000   53.045000   53.080000   \n2019-08-21 07:00:00-04:00   53.112500   53.112500   53.000000   53.070000   \n2019-08-21 08:00:00-04:00   53.050000   53.100000   53.000000   53.065000   \n...                               ...         ...         ...         ...   \n2021-08-20 13:30:00-04:00  147.912003  147.994995  147.550003  147.720001   \n2021-08-20 14:30:00-04:00  147.714996  148.165894  147.559998  148.084793   \n2021-08-20 15:30:00-04:00  148.087006  148.289993  147.945007  148.190002   \n2021-08-20 16:00:00-04:00  148.190000  148.300000  147.616000  148.190000   \n2021-08-20 17:00:00-04:00  148.170000  148.280000  142.382000  148.260000   \n\n                            Adj Close   volume    volume_adi  volume_obv  \\\nDatetime                                                                   \n2019-08-21 04:00:00-04:00   53.050000        0  0.000000e+00           0   \n2019-08-21 05:00:00-04:00   53.150000        0  0.000000e+00           0   \n2019-08-21 06:00:00-04:00   53.080000        0  0.000000e+00           0   \n2019-08-21 07:00:00-04:00   53.070000        0  0.000000e+00           0   \n2019-08-21 08:00:00-04:00   53.065000        0  0.000000e+00           0   \n...                               ...      ...           ...         ...   \n2021-08-20 13:30:00-04:00  147.720001  4405041  1.740461e+09   510276027   \n2021-08-20 14:30:00-04:00  148.084793  4758189  1.743945e+09   515034216   \n2021-08-20 15:30:00-04:00  148.190002  6188690  1.746547e+09   521222906   \n2021-08-20 16:00:00-04:00  148.190000  5268304  1.750120e+09   515954602   \n2021-08-20 17:00:00-04:00  148.260000        0  1.750120e+09   515954602   \n\n                           volume_cmf      volume_fi  ...  momentum_kama  \\\nDatetime                                              ...                  \n2019-08-21 04:00:00-04:00    0.000000       0.000000  ...      53.050000   \n2019-08-21 05:00:00-04:00    0.000000       0.000000  ...      53.094125   \n2019-08-21 06:00:00-04:00    0.000000       0.000000  ...      53.087931   \n2019-08-21 07:00:00-04:00    0.000000       0.000000  ...      53.080061   \n2019-08-21 08:00:00-04:00    0.000000       0.000000  ...      53.073436   \n...                               ...            ...  ...            ...   \n2021-08-20 13:30:00-04:00    0.054954  481052.780475  ...     146.998141   \n2021-08-20 14:30:00-04:00    0.033182  660295.049504  ...     147.190885   \n2021-08-20 15:30:00-04:00    0.170270  658982.621843  ...     147.387734   \n2021-08-20 16:00:00-04:00    0.332275  564840.409856  ...     147.540621   \n2021-08-20 17:00:00-04:00    0.235600  484148.922733  ...     147.626934   \n\n                           momentum_roc  momentum_ppo  momentum_ppo_signal  \\\nDatetime                                                                     \n2019-08-21 04:00:00-04:00      0.000000      0.000000             0.000000   \n2019-08-21 05:00:00-04:00      0.000000      0.000000             0.000000   \n2019-08-21 06:00:00-04:00      0.000000      0.000000             0.000000   \n2019-08-21 07:00:00-04:00      0.000000      0.000000             0.000000   \n2019-08-21 08:00:00-04:00      0.000000      0.000000             0.000000   \n...                                 ...           ...                  ...   \n2021-08-20 13:30:00-04:00      0.695297      6.479453            -5.881436   \n2021-08-20 14:30:00-04:00      1.047283      6.175124            -3.470124   \n2021-08-20 15:30:00-04:00      1.333426      8.251022            -1.125895   \n2021-08-20 16:00:00-04:00      1.188119      8.201423             0.739569   \n2021-08-20 17:00:00-04:00      1.263575     -1.120546             0.367546   \n\n                           momentum_ppo_hist  others_dr  others_dlr  \\\nDatetime                                                              \n2019-08-21 04:00:00-04:00           0.000000 -47.504397    0.000000   \n2019-08-21 05:00:00-04:00           0.000000   0.188501    0.188324   \n2019-08-21 06:00:00-04:00           0.000000  -0.131703   -0.131790   \n2019-08-21 07:00:00-04:00           0.000000  -0.018839   -0.018841   \n2019-08-21 08:00:00-04:00           0.000000  -0.009422   -0.009422   \n...                                      ...        ...         ...   \n2021-08-20 13:30:00-04:00          12.360889  -0.133651   -0.133740   \n2021-08-20 14:30:00-04:00           9.645248   0.246948    0.246644   \n2021-08-20 15:30:00-04:00           9.376917   0.071047    0.071021   \n2021-08-20 16:00:00-04:00           7.461854  -0.000002   -0.000002   \n2021-08-20 17:00:00-04:00          -1.488091   0.047237    0.047226   \n\n                            others_cr  close_shift  class_column  \nDatetime                                                          \n2019-08-21 04:00:00-04:00    0.000000      53.3475             0  \n2019-08-21 05:00:00-04:00    0.188501      53.2000             0  \n2019-08-21 06:00:00-04:00    0.056550      52.9025             0  \n2019-08-21 07:00:00-04:00    0.037700      53.0250             0  \n2019-08-21 08:00:00-04:00    0.028275      53.1950             0  \n...                               ...          ...           ...  \n2021-08-20 13:30:00-04:00  178.454291          NaN             0  \n2021-08-20 14:30:00-04:00  179.141929          NaN             0  \n2021-08-20 15:30:00-04:00  179.340250          NaN             0  \n2021-08-20 16:00:00-04:00  179.340245          NaN             0  \n2021-08-20 17:00:00-04:00  179.472196          NaN             0  \n\n[8377 rows x 91 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>Adj Close</th>\n      <th>volume</th>\n      <th>volume_adi</th>\n      <th>volume_obv</th>\n      <th>volume_cmf</th>\n      <th>volume_fi</th>\n      <th>...</th>\n      <th>momentum_kama</th>\n      <th>momentum_roc</th>\n      <th>momentum_ppo</th>\n      <th>momentum_ppo_signal</th>\n      <th>momentum_ppo_hist</th>\n      <th>others_dr</th>\n      <th>others_dlr</th>\n      <th>others_cr</th>\n      <th>close_shift</th>\n      <th>class_column</th>\n    </tr>\n    <tr>\n      <th>Datetime</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-08-21 04:00:00-04:00</th>\n      <td>52.775000</td>\n      <td>53.110000</td>\n      <td>52.775000</td>\n      <td>53.050000</td>\n      <td>53.050000</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>53.050000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-47.504397</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>53.3475</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2019-08-21 05:00:00-04:00</th>\n      <td>53.045000</td>\n      <td>53.150000</td>\n      <td>53.045000</td>\n      <td>53.150000</td>\n      <td>53.150000</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>53.094125</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.188501</td>\n      <td>0.188324</td>\n      <td>0.188501</td>\n      <td>53.2000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2019-08-21 06:00:00-04:00</th>\n      <td>53.152500</td>\n      <td>53.200000</td>\n      <td>53.045000</td>\n      <td>53.080000</td>\n      <td>53.080000</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>53.087931</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-0.131703</td>\n      <td>-0.131790</td>\n      <td>0.056550</td>\n      <td>52.9025</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2019-08-21 07:00:00-04:00</th>\n      <td>53.112500</td>\n      <td>53.112500</td>\n      <td>53.000000</td>\n      <td>53.070000</td>\n      <td>53.070000</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>53.080061</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-0.018839</td>\n      <td>-0.018841</td>\n      <td>0.037700</td>\n      <td>53.0250</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2019-08-21 08:00:00-04:00</th>\n      <td>53.050000</td>\n      <td>53.100000</td>\n      <td>53.000000</td>\n      <td>53.065000</td>\n      <td>53.065000</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>53.073436</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-0.009422</td>\n      <td>-0.009422</td>\n      <td>0.028275</td>\n      <td>53.1950</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2021-08-20 13:30:00-04:00</th>\n      <td>147.912003</td>\n      <td>147.994995</td>\n      <td>147.550003</td>\n      <td>147.720001</td>\n      <td>147.720001</td>\n      <td>4405041</td>\n      <td>1.740461e+09</td>\n      <td>510276027</td>\n      <td>0.054954</td>\n      <td>481052.780475</td>\n      <td>...</td>\n      <td>146.998141</td>\n      <td>0.695297</td>\n      <td>6.479453</td>\n      <td>-5.881436</td>\n      <td>12.360889</td>\n      <td>-0.133651</td>\n      <td>-0.133740</td>\n      <td>178.454291</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-08-20 14:30:00-04:00</th>\n      <td>147.714996</td>\n      <td>148.165894</td>\n      <td>147.559998</td>\n      <td>148.084793</td>\n      <td>148.084793</td>\n      <td>4758189</td>\n      <td>1.743945e+09</td>\n      <td>515034216</td>\n      <td>0.033182</td>\n      <td>660295.049504</td>\n      <td>...</td>\n      <td>147.190885</td>\n      <td>1.047283</td>\n      <td>6.175124</td>\n      <td>-3.470124</td>\n      <td>9.645248</td>\n      <td>0.246948</td>\n      <td>0.246644</td>\n      <td>179.141929</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-08-20 15:30:00-04:00</th>\n      <td>148.087006</td>\n      <td>148.289993</td>\n      <td>147.945007</td>\n      <td>148.190002</td>\n      <td>148.190002</td>\n      <td>6188690</td>\n      <td>1.746547e+09</td>\n      <td>521222906</td>\n      <td>0.170270</td>\n      <td>658982.621843</td>\n      <td>...</td>\n      <td>147.387734</td>\n      <td>1.333426</td>\n      <td>8.251022</td>\n      <td>-1.125895</td>\n      <td>9.376917</td>\n      <td>0.071047</td>\n      <td>0.071021</td>\n      <td>179.340250</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-08-20 16:00:00-04:00</th>\n      <td>148.190000</td>\n      <td>148.300000</td>\n      <td>147.616000</td>\n      <td>148.190000</td>\n      <td>148.190000</td>\n      <td>5268304</td>\n      <td>1.750120e+09</td>\n      <td>515954602</td>\n      <td>0.332275</td>\n      <td>564840.409856</td>\n      <td>...</td>\n      <td>147.540621</td>\n      <td>1.188119</td>\n      <td>8.201423</td>\n      <td>0.739569</td>\n      <td>7.461854</td>\n      <td>-0.000002</td>\n      <td>-0.000002</td>\n      <td>179.340245</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-08-20 17:00:00-04:00</th>\n      <td>148.170000</td>\n      <td>148.280000</td>\n      <td>142.382000</td>\n      <td>148.260000</td>\n      <td>148.260000</td>\n      <td>0</td>\n      <td>1.750120e+09</td>\n      <td>515954602</td>\n      <td>0.235600</td>\n      <td>484148.922733</td>\n      <td>...</td>\n      <td>147.626934</td>\n      <td>1.263575</td>\n      <td>-1.120546</td>\n      <td>0.367546</td>\n      <td>-1.488091</td>\n      <td>0.047237</td>\n      <td>0.047226</td>\n      <td>179.472196</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8377 rows × 91 columns</p>\n</div>"
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "higher_threshold = 1.5\n",
    "lowest_threshold = -1.5\n",
    "last_values_higher = []\n",
    "last_values_lower = []\n",
    "data['class_column'] = data.apply((lambda x: create_class_column(x, lowest_threshold, higher_threshold)), axis=1)\n",
    "while True:\n",
    "    # print(data['class_column'].value_counts())\n",
    "    class_counts = data['class_column'].value_counts()\n",
    "    if abs(class_counts[0] - class_counts[1]) < 15 and abs(class_counts[0] - class_counts[-1]) < 15:\n",
    "        break\n",
    "\n",
    "    if len(last_values_higher) == 3:\n",
    "        last_values_higher.pop(0)\n",
    "    if len(last_values_lower) == 3:\n",
    "        last_values_lower.pop(0)\n",
    "\n",
    "    last_values_higher.append(higher_threshold)\n",
    "    last_values_lower.append(lowest_threshold)\n",
    "    if class_counts[0] > class_counts[1]:\n",
    "        higher_threshold -= 0.01\n",
    "    if class_counts[0] > class_counts[-1]:\n",
    "        lowest_threshold += 0.01\n",
    "    if class_counts[0] < class_counts[1]:\n",
    "        higher_threshold += 0.01\n",
    "    if class_counts[0] < class_counts[-1]:\n",
    "        lowest_threshold -= 0.01\n",
    "\n",
    "    if higher_threshold in last_values_higher and lowest_threshold in last_values_lower:\n",
    "        break\n",
    "    # print(higher_threshold, lowest_threshold)\n",
    "    data['class_column'] = data.apply((lambda x: create_class_column(x, lowest_threshold, higher_threshold)), axis=1)\n",
    "\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "outputs": [
    {
     "data": {
      "text/plain": " 0    2817\n 1    2802\n-1    2758\nName: class_column, dtype: int64"
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class divide\n",
    "data['class_column'] = data.apply((lambda x: create_class_column(x, lowest_threshold, higher_threshold)), axis=1)\n",
    "\n",
    "data['class_column'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\Desktop\\repo\\magisterka_analiza\\data\\results\\train_test\\AAPL_2y_16_diff_20_08_2021 23_13_39_full.csv\n"
     ]
    }
   ],
   "source": [
    "filename_to_export = f'C:\\\\Users\\\\exomat\\\\Desktop\\\\repo\\\\magisterka_analiza\\\\data\\\\results\\\\train_test\\\\{symbol}_{INTERVAL}_{WINDOW}_diff_{datetime.now().strftime(\"%d_%m_%Y %H_%M_%S\")}_full.csv'\n",
    "data.to_csv(filename_to_export, index=True)\n",
    "print(filename_to_export)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "outputs": [
    {
     "data": {
      "text/plain": " 0    2817\n 1    2802\n-1    2758\nName: class_column, dtype: int64"
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Class divide\n",
    "data['class_column'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "outputs": [],
   "source": [
    "# del (data['close'])\n",
    "del (data['close_shift'])\n",
    "data = data.dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "outputs": [
    {
     "data": {
      "text/plain": " 0    2817\n 1    2802\n-1    2758\nName: class_column, dtype: int64"
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class_column'].value_counts()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "outputs": [],
   "source": [
    "y = data['class_column']\n",
    "features = [x for x in data.columns if x not in ['class_column']]\n",
    "x = data[features]\n",
    "# scaler = MinMaxScaler()\n",
    "# x = pd.DataFrame(scaler.fit_transform(x.values), columns=x.columns, index=x.index)\n",
    "ROWS_TO_PREDICT = 512\n",
    "if ROWS_TO_PREDICT == 33:\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x, y, test_size=0.3, shuffle=False)\n",
    "else:\n",
    "    x_train= x.iloc[:-ROWS_TO_PREDICT]\n",
    "    y_train= y.iloc[:-ROWS_TO_PREDICT]\n",
    "    x_test =x.iloc[-ROWS_TO_PREDICT:]\n",
    "    y_test=y.iloc[-ROWS_TO_PREDICT:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "outputs": [],
   "source": [
    "classifiers = dict()\n",
    "classifiers['DecisionTreeClassifier 1'] = DecisionTreeClassifier(max_depth=15, random_state=0, criterion='gini',\n",
    "                                                                 splitter='best')\n",
    "classifiers['DecisionTreeClassifier 2'] = DecisionTreeClassifier(max_depth=40, random_state=0, criterion='gini',\n",
    "                                                                 splitter='best')\n",
    "classifiers['DecisionTreeClassifier 3'] = DecisionTreeClassifier(max_depth=10, random_state=0,criterion='gini',splitter='best')\n",
    "\n",
    "\n",
    "classifiers['RandomForestClassifier 1'] = RandomForestClassifier(n_estimators=1000, max_depth=3, random_state=0,\n",
    "                                                                 criterion='gini', n_jobs=-1)\n",
    "\n",
    "classifiers['RandomForestClassifier 2'] = RandomForestClassifier(n_estimators=1000, max_depth=3, random_state=0,\n",
    "                                                                 criterion='entropy', n_jobs=-1)\n",
    "\n",
    "classifiers['RandomForestClassifier 3'] = RandomForestClassifier(n_estimators=100, max_depth=15, random_state=0,\n",
    "                                                                 criterion='entropy', n_jobs=-1)\n",
    "\n",
    "\n",
    "classifiers['GradientBoostingClassifier 1'] = GradientBoostingClassifier(n_estimators=100, random_state=0,\n",
    "                                                                         criterion='friedman_mse', max_depth=3,\n",
    "                                                                         learning_rate=0.1)\n",
    "\n",
    "classifiers['GradientBoostingClassifier 2'] = GradientBoostingClassifier(n_estimators=1000, random_state=0,\n",
    "                                                                         criterion='friedman_mse', max_depth=3,\n",
    "                                                                         learning_rate=0.5)\n",
    "\n",
    "\n",
    "classifiers['XGBRFClassifier 1'] = xgb.sklearn.XGBRFClassifier(n_jobs=-1, max_depth=2, n_estimators=1000, eta=0.2)\n",
    "classifiers['XGBRFClassifier 2'] = xgb.sklearn.XGBRFClassifier(n_jobs=-1, max_depth=6, n_estimators=1000, eta=0.3)\n",
    "\n",
    "classifiers['XGBClassifier 1'] = xgb.XGBClassifier(nthread=-1, max_depth=3, n_estimators=1000, eta=0.2)\n",
    "classifiers['XGBClassifier 2'] = xgb.XGBClassifier(nthread=-1, max_depth=3, n_estimators=1000, eta=0.3)\n",
    "\n",
    "classifiers_boosted = dict()\n",
    "classifiers_boosted['GradientBoostingClassifier 1S'] = GradientBoostingClassifier(n_estimators=100, random_state=0,\n",
    "                                                                                  criterion='friedman_mse', max_depth=3,\n",
    "                                                                                  learning_rate=0.1)\n",
    "classifiers_boosted['SXGBClassifier 1'] = xgb.XGBClassifier(nthread=-1, max_depth=3, n_estimators=1000, eta=0.2)\n",
    "classifiers_boosted['SXGBClassifier 2'] = xgb.XGBClassifier(nthread=-1, max_depth=3, n_estimators=1000, eta=0.3)\n",
    "classifiers_boosted['SXGBClassifier 3'] = xgb.XGBClassifier(nthread=-1, max_depth=10, n_estimators=1000, eta=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "outputs": [],
   "source": [
    "def print_conf_matrix(test_y, predict, name):\n",
    "    matrix = confusion_matrix(test_y, predict,  labels=[-1, 0, 1])\n",
    "    print(matrix)\n",
    "    ax= plt.subplot()\n",
    "    sn.heatmap(matrix, annot=True, ax = ax) #annot=True to annotate cells\n",
    "\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels', color='white')\n",
    "    ax.set_ylabel('True labels', color='white')\n",
    "    ax.set_title(f'Confusion Matrix for {name}' , color='white')\n",
    "    ax.xaxis.set_ticklabels(['-1','0', '1'], color='white')\n",
    "    ax.yaxis.set_ticklabels(['-1','0', '1'], color='white')\n",
    "    plt.show()\n",
    "\n",
    "def train_model(model,train_x, train_y):\n",
    "    model.fit(train_x, train_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "outputs": [],
   "source": [
    "predictions_train= dict()\n",
    "score_train = dict()\n",
    "predictions= dict()\n",
    "score = dict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "outputs": [],
   "source": [
    "# predictions_train= dict()\n",
    "# score_train = dict()\n",
    "# predictions= dict()\n",
    "# score = dict()\n",
    "# for k,v in classifiers.items():\n",
    "#     print(\"Calculate: \", k)\n",
    "#     train_model(v,x_train,y_train)\n",
    "#     predictions_train[k] = v.predict(x_train)\n",
    "#     score_train[k] = accuracy_score(y_train.values, predictions_train[k])\n",
    "#     predictions[k] = v.predict(x_test)\n",
    "#     score[k] = accuracy_score(y_test.values, predictions[k])\n",
    "#     print('Score_train: ',  score_train[k] )\n",
    "#     print('Score: ',  score[k] )\n",
    "#     # print_conf_matrix(test_y, predictions[k], k)\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "outputs": [],
   "source": [
    "# filename_to_export = f'C:\\\\Users\\\\exomat\\\\Desktop\\\\repo\\\\magisterka_analiza\\\\data\\\\results\\\\train_test\\\\result_test_xrand_{symbol}_{WINDOW}_{ROWS_TO_PREDICT}_{datetime.now().strftime(\"%d_%m_%Y %H_%M_%S\")}.csv'\n",
    "# filename_to_export_train= f'C:\\\\Users\\\\exomat\\\\Desktop\\\\repo\\\\magisterka_analiza\\\\data\\\\results\\\\train_test\\\\result_train_xrand_{symbol}_{WINDOW}_{ROWS_TO_PREDICT}_{datetime.now().strftime(\"%d_%m_%Y %H_%M_%S\")}.csv'\n",
    "#\n",
    "# headers = [\"Classifier type\", \"Accuracy\"]\n",
    "# score_df = pd.DataFrame(score.items(), columns=headers)\n",
    "# print(tabulate(score_df, headers, tablefmt=\"psql\"))\n",
    "# score_df.to_csv(filename_to_export,mode='a', index=False, header=False)\n",
    "# score_df_train = pd.DataFrame(score_train.items(), columns=headers)\n",
    "# print(tabulate(score_df_train, headers, tablefmt=\"psql\"))\n",
    "# score_df_train.to_csv(filename_to_export_train,mode='a', index=False, header=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass n_features_to_select=10 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:14:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:14:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:15:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:15:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:15:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:15:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:16:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:16:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:16:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:16:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:17:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:17:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:17:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:17:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:18:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:18:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:18:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:18:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:18:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:19:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:19:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:19:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:19:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:20:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:20:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:20:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:20:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:20:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:21:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:21:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:21:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:21:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:22:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:22:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:22:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:22:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:22:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:23:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:23:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:23:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:23:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:23:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:23:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:24:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:24:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:24:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:24:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:24:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:24:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:24:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:25:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:25:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:25:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:25:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:25:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:25:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:25:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:26:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:26:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:26:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:26:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:26:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:26:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:26:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:27:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:27:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:27:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:27:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:27:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:27:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:27:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:27:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:27:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:27:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:27:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:28:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exomat\\anaconda3\\envs\\magisterka_analiza\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:28:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "RFE(estimator=XGBRFClassifier(base_score=None, booster=None,\n                              colsample_bylevel=None, colsample_bytree=None,\n                              eta=0.6, gamma=None, gpu_id=None,\n                              importance_type='gain',\n                              interaction_constraints=None, max_delta_step=None,\n                              max_depth=3, min_child_weight=None, missing=nan,\n                              monotone_constraints=None, n_estimators=1000,\n                              n_jobs=-1, num_parallel_tree=None,\n                              objective='binary:logistic', random_state=None,\n                              reg_alpha=None, scale_pos_weight=None,\n                              tree_method=None, validate_parameters=None,\n                              verbosity=None),\n    n_features_to_select=10)"
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe = RFE(classifiers['XGBRFClassifier 6'],10)\n",
    "fited = rfe.fit(x_train, y_train)\n",
    "rfe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with predictive power: ['open', 'low', 'volume_adi', 'volume_obv', 'volume_cmf', 'volume_nvi', 'volatility_atr', 'volatility_kcl', 'volatility_ui', 'momentum_kama']\n"
     ]
    },
    {
     "data": {
      "text/plain": "['open',\n 'low',\n 'volume_adi',\n 'volume_obv',\n 'volume_cmf',\n 'volume_nvi',\n 'volatility_atr',\n 'volatility_kcl',\n 'volatility_ui',\n 'momentum_kama',\n 'high',\n 'low',\n 'volume',\n 'open']"
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = x.columns\n",
    "columns=[]\n",
    "for i in range(len(fited.support_)):\n",
    "    if fited.support_[i]:\n",
    "        columns.append(names[i])\n",
    "\n",
    "print(\"Columns with predictive power:\", columns )\n",
    "columns = columns + ['high', 'low', 'volume', 'open']\n",
    "columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "outputs": [],
   "source": [
    "x_test_cropped = x_test[columns]\n",
    "x_train_cropped = x_train[columns]\n",
    "x_train_cropped\n",
    "x_test_cropped = x_test_cropped.loc[:,~x_test_cropped.columns.duplicated()]\n",
    "x_train_cropped = x_train_cropped.loc[:,~x_train_cropped.columns.duplicated()]\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate:  SXGBClassifier 1\n",
      "[23:28:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Score train:  0.9762237762237762\n",
      "Score:  0.369140625\n",
      "Calculate:  SXGBClassifier 2\n",
      "[23:28:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Score train:  0.9960584869675779\n",
      "Score:  0.396484375\n",
      "Calculate:  SXGBClassifier 3\n",
      "[23:28:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Score train:  1.0\n",
      "Score:  0.40234375\n",
      "+----+-------------------+------------+\n",
      "|    | Classifier type   |   Accuracy |\n",
      "|----+-------------------+------------|\n",
      "|  0 | SXGBClassifier 1  |   0.369141 |\n",
      "|  1 | SXGBClassifier 2  |   0.396484 |\n",
      "|  2 | SXGBClassifier 3  |   0.402344 |\n",
      "+----+-------------------+------------+\n",
      "+----+-------------------+------------+\n",
      "|    | Classifier type   |   Accuracy |\n",
      "|----+-------------------+------------|\n",
      "|  0 | SXGBClassifier 1  |   0.976224 |\n",
      "|  1 | SXGBClassifier 2  |   0.996058 |\n",
      "|  2 | SXGBClassifier 3  |   1        |\n",
      "+----+-------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "for k,v in classifiers_boosted.items():\n",
    "    print(\"Calculate: \", k)\n",
    "    train_model(v,x_train_cropped,y_train)\n",
    "    predictions_train[k] = v.predict(x_train_cropped)\n",
    "    score_train[k] = accuracy_score(y_train.values, predictions_train[k])\n",
    "    predictions[k] = v.predict(x_test_cropped)\n",
    "    score[k] = accuracy_score(y_test.values, predictions[k])\n",
    "    print('Score train: ',  score_train[k] )\n",
    "    print('Score: ',  score[k] )\n",
    "    # print_conf_matrix(test_y, predictions[k], k)\n",
    "\n",
    "filename_to_export = f'C:\\\\Users\\\\exomat\\\\Desktop\\\\repo\\\\magisterka_analiza\\\\data\\\\results\\\\train_test\\\\result_test_s_{symbol}_{WINDOW}_{ROWS_TO_PREDICT}_{datetime.now().strftime(\"%d_%m_%Y %H_%M_%S\")}.csv'\n",
    "filename_to_export_train= f'C:\\\\Users\\\\exomat\\\\Desktop\\\\repo\\\\magisterka_analiza\\\\data\\\\results\\\\train_test\\\\result_train_s_{symbol}_{WINDOW}_{ROWS_TO_PREDICT}_{datetime.now().strftime(\"%d_%m_%Y %H_%M_%S\")}.csv'\n",
    "\n",
    "headers = [\"Classifier type\", \"Accuracy\"]\n",
    "score_df = pd.DataFrame(score.items(), columns=headers)\n",
    "print(tabulate(score_df, headers, tablefmt=\"psql\"))\n",
    "score_df.to_csv(filename_to_export,mode='a', index=False, header=False)\n",
    "score_df_train = pd.DataFrame(score_train.items(), columns=headers)\n",
    "print(tabulate(score_df_train, headers, tablefmt=\"psql\"))\n",
    "score_df_train.to_csv(filename_to_export_train,mode='a', index=False, header=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['open', 'low', 'volume_adi', 'volume_obv', 'volume_cmf', 'volume_nvi',\n       'volatility_atr', 'volatility_kcl', 'volatility_ui', 'momentum_kama',\n       'high', 'volume'],\n      dtype='object')"
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_cropped.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "outputs": [],
   "source": [
    "#\n",
    "# model = xgb.XGBClassifier(nthread =-1,max_depth=14,n_estimators=1000,\n",
    "#                           eta =0.2)\n",
    "# model.fit(x_train,y_train)\n",
    "# predicted_train = model.predict(x_train)\n",
    "# predicted_test = model.predict(x_test)\n",
    "# print(\"------------\")\n",
    "# print(f'max_depth: {14}')\n",
    "# score_train['XGBClassifier'] = accuracy_score(y_train.values, predicted_train)\n",
    "# score['XGBClassifier'] = accuracy_score(y_test.values, predicted_test)\n",
    "# print(score_train['XGBClassifier'])\n",
    "# print(score['XGBClassifier'])\n",
    "# print(\"------------\")\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "outputs": [],
   "source": [
    "# model = xgb.sklearn.XGBRFClassifier(n_jobs=-1,max_depth=12,n_estimators =100,eta=0.4)\n",
    "# model.fit(x_train,y_train)\n",
    "# predicted_train = model.predict(x_train)\n",
    "# predicted_test = model.predict(x_test)\n",
    "# print(\"------------\")\n",
    "# print(f'eta: ')\n",
    "# score_train['XGBRFClassifier'] = accuracy_score(y_train.values, predicted_train)\n",
    "# score['XGBRFClassifier'] = accuracy_score(y_test.values, predicted_test)\n",
    "# print(accuracy_score(y_train.values, predicted_train))\n",
    "# print(accuracy_score(y_test.values, predicted_test))\n",
    "# print(\"------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}